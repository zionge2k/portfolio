---
title: "외부 API 대량 수집 설계 - Rate Limit 안에서 최적화하기"
description: "Rate Limit 제약 하에서 외부 API 대량 수집 로직을 설계하고, 시뮬레이션으로 이론적 한계를 증명한 과정"
date: "2026-02-10"
tags: ["java", "api", "rate-limit", "concurrency", "optimization"]
published: true
---

## 시나리오

프로덕트의 컨텐츠를 풍부하게 하기 위해 외부 API(고용24)에서 상품 후기 데이터를 수집해야 했다. 대상 상품 1,100개, 각 상품마다 차수별 후기를 개별 호출해야 하므로 총 호출 수가 수천 건에 달하는 배치 작업이다.

## 제약 조건

수집 구조를 설계하기 전에 확인한 제약 조건:

| 항목 | 내용 |
|------|------|
| Rate Limit | 스레드당 500ms 간격, 최대 3스레드 (초당 6회) |
| 호출 구조 | 공식 API(상품 검색) + 비공식 API(차수별 후기) |
| 차수 조회 | 차수별 개별 호출 필수 (전체 조회 API 없음, 직접 확인) |
| 후기 분포 | 상품당 0~30건, 평균 ~6.5차수 |

핵심 제약은 **차수별 개별 호출**이다. 상품 하나의 후기를 한 번에 가져오는 API가 없어서, 차수마다 별도 호출이 필요하다. 이건 API 문서가 아니라 직접 호출해서 확인한 결과다.

## Phase 1: 비최적화 상태 (~29분)

초기 구현은 단순했다. 3스레드가 상품을 균등 분배받아 순차 처리하는 방식.

두 가지 비효율이 있었다:

**1. 중복 호출**: 공식 API 검색 결과에 동일 상품이 여러 번 등장. 이미 처리한 상품을 다시 호출.

**2. 스레드 idle**: 상품별 차수 수가 불균형. 한 스레드는 30차수 상품을 처리하는 동안 다른 스레드는 이미 끝나고 대기.

```
Thread 1: [상품A 검색][A 1차][A 2차]...[A 30차]  ← 아직 진행 중
Thread 2: [상품B 검색][B 1차][B 2차][idle........]  ← 대기
Thread 3: [상품C 검색][C 1차][idle................]  ← 대기
           ──────────── 시간 ────────────────────→
```

스레드 2, 3이 놀고 있어도 Rate Limit 슬롯은 점유된다. 결과적으로 초당 6회 중 2~4회가 낭비.

## Phase 2: 최적화 (~23분)

### 중복 호출 제거

매칭 완료된 상품 ID를 `Set`으로 추적. 검색 결과에서 이미 처리한 상품은 건너뛴다.

### 동적 작업 할당

상품을 스레드에 미리 분배하지 않고, 공유 큐에서 꺼내가는 방식으로 변경. 한 스레드가 작업을 끝내면 즉시 다음 상품을 가져간다.

```
Thread 1: [상품A 검색][A 1차][A 2차][상품D 검색][D 1차]...
Thread 2: [상품B 검색][B 1차][B 2차][B 3차][상품E 검색]...
Thread 3: [상품C 검색][C 1차][상품F 검색][F 1차][F 2차]...
           ──────────── 시간 ────────────────────→
```

스레드가 쉬지 않고 계속 호출. Rate Limit 슬롯을 최대한 활용한다.

결과: **~29분 → ~23분** (6분 절약).

## Phase 3: 이론적 한계 검증

23분이 더 줄어들 수 있는지 확인하기 위해 이론적 최소 시간을 계산했다.

### 총 API 호출 수

| 호출 유형 | 건수 | 산출 근거 |
|-----------|------|-----------|
| 상품 검색 (공식 API) | 1,100회 | 상품 1,100개 × 1회 |
| 차수별 후기 (비공식 API) | ~7,150회 | 상품당 평균 6.5차수 |
| **합계** | **~8,250회** | |

### 이론적 최소 시간

```
총 호출 수 / 초당 처리량 = 소요 시간

8,250회 / 6회(초당) = 1,375초 ≈ 22.9분
```

현재 달성 시간 23분은 이론적 최소 시간과 거의 동일하다. **Rate Limit를 100% 활용하고 있으므로 동일 조건에서 추가 속도 개선은 불가능**하다.

## 추가 최적화 가능성 탐색

이론적 한계에 도달했지만, 호출 수 자체를 줄일 수 있는지 검토했다.

### 전체 통계 API?

차수별이 아닌 상품 전체의 후기를 한 번에 가져오는 API가 있다면 호출 수를 대폭 줄일 수 있다. 하지만 직접 확인한 결과 **그런 API는 존재하지 않았다**. 차수별 개별 호출만 가능.

### ID 캐싱

공식 API 검색은 상품명 → 상품 ID 매핑이 목적이다. 한번 매핑된 ID를 캐싱하면 재실행 시 검색 호출 1,100회를 생략할 수 있다.

```
(8,250 - 1,100) / 6 = 1,192초 ≈ 19.9분
```

재실행 시 ~20분, 약 3분 절약. 신규 상품만 검색하면 된다.

### Rate Limit 완화?

스레드를 늘리거나 간격을 줄이면 빨라지지만, **API 키 차단 리스크**가 있다. 특히 비공식 API는 명시적 Rate Limit 문서가 없어서 현재 값(500ms, 3스레드)은 안전 마진을 포함한 경험적 설정이다. 비추천.

## 운영 관점: 속도 다음에 해야 할 것

속도 한계에 도달하면 관점을 전환해야 한다. "더 빠르게"가 아니라 "안정적으로, 효율적으로".

### 비공식 API 의존 리스크

가장 위험한 부분. 비공식 API는 사전 고지 없이 스펙이 변경되거나 차단될 수 있다.

- **응답 스키마 검증**: 수집 시 필수 필드가 누락되면 즉시 알림. 조용히 빈 데이터가 적재되는 게 가장 위험
- **수집 건수 모니터링**: 일일 수집 건수가 평소 대비 급감하면 API 변경 의심
- **Fallback**: 비공식 API가 막혀도 캐싱된 기존 데이터로 서비스 유지. 후기가 없어지는 것과 서비스가 깨지는 것은 다른 문제

### 실패 복구 (Checkpoint)

23분짜리 배치가 20분째에 실패하면 처음부터 다시 도는 건 치명적.

- **진행 상태 저장**: 처리 완료된 상품 ID를 기록하고, 재시작 시 이어서 처리
- **부분 실패 격리**: 특정 상품 호출이 실패해도 전체 배치를 중단하지 않는다. 실패 건만 모아서 배치 종료 후 재처리
- **지수 백오프**: 연속 실패 시 호출 간격을 500ms → 1s → 2s로 늘려서 API 키 차단 방지

### 증분 업데이트

매번 1,100개 전체를 수집할 필요 없다.

- **변경 감지**: 마지막 수집 이후 새 차수가 열린 상품만 대상으로
- **전체 동기화 주기**: 증분만 하면 데이터 drift가 쌓이므로, 주기적으로 전체 수집을 돌려 정합성 확보

## 핵심 정리

Rate Limit 환경에서 최적화의 끝은 **"한계를 증명하는 것"**이다.

현재 상태를 수식으로 검증할 수 있으면, "더 빠르게"라는 질문에 근거 있는 답을 줄 수 있다. 23분이 느려 보여도, 초당 6회 제약에서 8,250회를 처리하는 이론적 최소가 22.9분이면 할 수 있는 건 다 한 것이다.

속도 한계에 도달했으면 운영 안정성으로 관점을 전환한다. 비공식 API가 언제 바뀔지 모르므로 **모니터링과 Fallback이 최우선**, 그 다음이 Checkpoint를 통한 실패 복구, 마지막이 증분 업데이트를 통한 효율화다.
