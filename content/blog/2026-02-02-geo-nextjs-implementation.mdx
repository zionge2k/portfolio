---
title: "GEO 실전: Next.js에서 AI 검색 최적화 적용하기"
description: "AI 크롤러 허용, llms.txt 구현, 인용 가능한 콘텐츠 구조, FAQ 스키마, E-E-A-T 시그널까지. Next.js 포트폴리오에 GEO를 적용하는 구체적인 방법."
date: "2026-02-02"
tags: ["geo", "seo", "nextjs", "llms-txt"]
published: true
---

## 이 글의 위치

- [1편](/blog/2026-02-01-seo-fundamentals) — SEO 기초
- [2편](/blog/2026-02-02-seo-nextjs-metadata) — Next.js SEO 실전
- [3편](/blog/2026-02-02-seo-jsonld-core-web-vitals) — JSON-LD와 Core Web Vitals
- [4편](/blog/2026-02-02-geo-fundamentals) — GEO 기초: AI 검색의 동작 원리

4편에서 GEO의 원리와 전략을 다뤘다. 이 글에서는 Next.js에 실제로 적용한다.

---

## 1. AI 크롤러 허용

AI 검색엔진은 자체 크롤러로 웹을 수집한다. `robots.txt`에서 이 크롤러들을 차단하면 인용 대상에서 제외된다.

### 주요 AI 크롤러

| 크롤러 | 소속 |
|--------|------|
| `GPTBot` | OpenAI (ChatGPT) |
| `ChatGPT-User` | ChatGPT 브라우징 모드 |
| `Google-Extended` | Google AI (Gemini, AI Overview) |
| `PerplexityBot` | Perplexity |
| `ClaudeBot` | Anthropic (Claude) |
| `Bytespider` | ByteDance (TikTok AI) |

### Next.js에서 설정

```ts
// app/robots.ts
import type { MetadataRoute } from 'next'

export default function robots(): MetadataRoute.Robots {
  return {
    rules: [
      {
        userAgent: '*',
        allow: '/',
        disallow: '/api/',
      },
      // AI 크롤러를 명시적으로 허용
      {
        userAgent: 'GPTBot',
        allow: '/',
      },
      {
        userAgent: 'Google-Extended',
        allow: '/',
      },
      {
        userAgent: 'PerplexityBot',
        allow: '/',
      },
      {
        userAgent: 'ClaudeBot',
        allow: '/',
      },
    ],
    sitemap: 'https://example.com/sitemap.xml',
  }
}
```

AI 크롤러를 **별도 규칙으로 명시**하면, 일반 크롤러 규칙과 독립적으로 관리할 수 있다. 예를 들어 나중에 일반 크롤러는 일부 경로를 막되, AI 크롤러에는 열어두는 것이 가능하다.

## 2. llms.txt 구현

**llms.txt**는 2024년 9월에 제안된 새로운 표준이다. `robots.txt`가 "어디를 크롤링할 수 있는가"를 알려준다면, `llms.txt`는 "이 사이트에서 가장 중요한 콘텐츠가 무엇인가"를 AI에게 알려준다.

### 형식

Markdown으로 작성한다. 사이트 루트(`/llms.txt`)에 배치한다.

```markdown
# 이성 - Frontend Developer

> 프론트엔드 개발자 이성의 포트폴리오 사이트입니다.
> Next.js, TypeScript, React를 주로 사용합니다.

## Blog

- [SEO 기초: 검색엔진의 동작 원리](/blog/2026-02-01-seo-fundamentals): 크롤링, 인덱싱, 랭킹의 기본 개념
- [Next.js SEO 실전](/blog/2026-02-02-seo-nextjs-metadata): Metadata API, sitemap, Open Graph 설정
- [GEO 기초](/blog/2026-02-02-geo-fundamentals): AI 검색 시대의 콘텐츠 최적화

## About

- [소개](/about): 경력, 기술 스택, 프로젝트 이력
```

### Next.js에서 구현

App Router의 Route Handler로 동적 생성할 수 있다.

```ts
// app/llms.txt/route.ts
import { getAllPosts } from '@/lib/blog'

export function GET() {
  const posts = getAllPosts()

  const blogEntries = posts
    .map(
      (post) =>
        `- [${post.frontmatter.title}](/blog/${post.slug}): ${post.frontmatter.description}`
    )
    .join('\n')

  const content = `# 이성 - Frontend Developer

> 프론트엔드 개발자 이성의 포트폴리오 사이트입니다.

## Blog

${blogEntries}

## About

- [소개](/about): 경력, 기술 스택, 프로젝트 이력
`

  return new Response(content, {
    headers: {
      'Content-Type': 'text/plain; charset=utf-8',
    },
  })
}
```

블로그 글이 추가될 때마다 자동으로 `llms.txt`가 업데이트된다.

### llms.txt의 현재 상태

아직 초기 단계다. 주요 AI 플랫폼이 공식적으로 지원을 확인하지는 않았다. 하지만 Anthropic, Vercel, Hugging Face 등이 이미 채택하고 있고, `robots.txt`가 선택에서 필수가 된 것처럼 발전할 가능성이 있다. 구현 비용이 거의 없으니 미리 적용해두는 것이 합리적이다.

## 3. 인용 가능한 콘텐츠 구조

4편에서 다뤘듯이 AI 검색엔진은 **문서 전체가 아닌 청크(문단) 단위**로 콘텐츠를 추출한다. 각 문단이 독립적으로 의미를 전달할 수 있어야 한다.

### 답변 우선 포맷

각 섹션의 첫 40~60단어에 핵심 답변을 넣는다.

```markdown
<!-- Bad: 결론이 뒤에 나옴 -->
## Next.js의 렌더링 방식

웹 프레임워크는 크게 CSR, SSR, SSG로 나눌 수 있다.
CSR은 클라이언트에서 렌더링하고, SSR은 서버에서...
(중략)
...따라서 Next.js는 SSR과 SSG를 기본으로 지원한다.
```

```markdown
<!-- Good: 핵심이 첫 문장에 나옴 -->
## Next.js의 렌더링 방식

Next.js는 SSR과 SSG를 기본으로 지원하며,
App Router에서는 Server Components가 기본 렌더링 방식이다.
이를 통해 초기 로딩 속도와 SEO를 동시에 최적화할 수 있다.
```

AI가 "Next.js 렌더링 방식"을 질문받으면, 첫 문단을 그대로 인용할 수 있다.

### 질문형 헤딩

사용자가 AI에게 실제로 물어볼 법한 질문을 헤딩으로 사용한다.

```markdown
<!-- Bad: 일반적인 헤딩 -->
## 배경
## 설정 방법
## 결론

<!-- Good: 질문형 헤딩 -->
## Next.js에서 metadata는 어떻게 설정하는가
## generateMetadata와 정적 metadata의 차이는 무엇인가
## 레이아웃 간 metadata는 어떻게 병합되는가
```

### 구조화된 나열

목록, 테이블, 번호를 적극적으로 사용한다. AI는 구조화된 정보를 **28~40% 더 자주 인용**한다.

```markdown
Next.js에서 SEO를 설정하는 3단계:

1. `metadata` 또는 `generateMetadata`로 title, description 설정
2. `robots.ts`와 `sitemap.ts`로 크롤러 가이드
3. Open Graph와 JSON-LD로 리치 결과 지원
```

### 문단 길이

한 문단은 **60~100단어(한국어 기준 150~250자)** 가 적당하다. AI가 하나의 청크로 추출하기 좋은 크기다. 너무 길면 잘리고, 너무 짧으면 맥락이 부족하다.

## 4. 데이터와 출처 포함

4편의 연구 결과에서 가장 효과적이었던 전략 세 가지는 모두 **"검증 가능한 정보를 제공하는 것"** 이었다.

### 통계와 수치

```markdown
<!-- Bad -->
React는 프론트엔드에서 매우 인기 있는 라이브러리다.

<!-- Good -->
React는 Stack Overflow 2024 Developer Survey에서
프론트엔드 프레임워크 사용률 1위(39.5%)를 기록했다.
```

### 외부 출처 인용

글 하나에 **5~8개의 신뢰할 수 있는 외부 출처**를 포함하는 것이 권장된다.

신뢰도 높은 출처:
- 공식 문서 (Next.js Docs, MDN, React Docs)
- 학술 논문 (.edu, arXiv)
- 공신력 있는 블로그 (web.dev, Vercel Blog)
- 공식 보고서 (State of JS, Stack Overflow Survey)

### 전문가 인용

```markdown
Vercel CEO Guillermo Rauch는
"Server Components는 웹의 미래를 바꿀 기술"이라고 말했다.
```

## 5. FAQ 섹션과 Schema

FAQ는 GEO에서 특히 효과적이다. 사용자의 질문과 AI의 검색 쿼리가 직접 매칭되기 때문이다.

### 블로그 글에 FAQ 추가

글 하단에 관련 질문 5~10개를 추가한다. 각 답변은 40~60단어로 간결하게.

```markdown
## 자주 묻는 질문

### Next.js에서 SEO를 설정하려면 어떻게 해야 하나요?

App Router의 Metadata API를 사용한다.
`export const metadata` 객체로 정적 메타데이터를 설정하거나,
`generateMetadata` 함수로 동적 메타데이터를 생성할 수 있다.
`title.template`을 루트 레이아웃에 설정하면
모든 페이지에 일관된 제목 형식이 적용된다.

### SSR이 SEO에 왜 중요한가요?

검색엔진 크롤러는 JavaScript를 완벽하게 실행하지 못할 수 있다.
SSR은 서버에서 완성된 HTML을 보내므로,
크롤러가 JS 없이도 모든 콘텐츠를 읽을 수 있다.
```

### FAQPage Schema

FAQ에 구조화 데이터를 추가하면 인용 가능성이 크게 올라간다.

```tsx
const faqJsonLd = {
  '@context': 'https://schema.org',
  '@type': 'FAQPage',
  mainEntity: [
    {
      '@type': 'Question',
      name: 'Next.js에서 SEO를 설정하려면 어떻게 해야 하나요?',
      acceptedAnswer: {
        '@type': 'Answer',
        text: 'App Router의 Metadata API를 사용한다. export const metadata 객체로 정적 메타데이터를 설정하거나, generateMetadata 함수로 동적 메타데이터를 생성할 수 있다.',
      },
    },
    {
      '@type': 'Question',
      name: 'SSR이 SEO에 왜 중요한가요?',
      acceptedAnswer: {
        '@type': 'Answer',
        text: '검색엔진 크롤러는 JavaScript를 완벽하게 실행하지 못할 수 있다. SSR은 서버에서 완성된 HTML을 보내므로, 크롤러가 JS 없이도 모든 콘텐츠를 읽을 수 있다.',
      },
    },
  ],
}
```

GPT-4 기준으로, 구조화 데이터가 있으면 정확한 응답 비율이 **16%에서 54%로** 올라간다는 연구 결과가 있다.

## 6. E-E-A-T 시그널 강화

**E-E-A-T**: Experience(경험), Expertise(전문성), Authoritativeness(권위), Trustworthiness(신뢰)

Google AI Overview 인용의 **96%** 가 E-E-A-T 시그널이 강한 출처에서 나온다. 포트폴리오 사이트에서 이를 강화하는 방법:

### 저자 정보 페이지

소개 페이지에 경력, 기술 스택, 프로젝트 이력을 구체적으로 작성한다.

```tsx
// Person Schema를 about 페이지에 추가
const personJsonLd = {
  '@context': 'https://schema.org',
  '@type': 'Person',
  name: '이성',
  jobTitle: 'Frontend Developer',
  url: 'https://example.com',
  sameAs: [
    'https://github.com/username',
    'https://linkedin.com/in/username',
  ],
  knowsAbout: ['React', 'Next.js', 'TypeScript', 'Web Performance'],
}
```

### 일관된 저자 귀속

모든 블로그 글에 동일한 저자 정보를 연결한다.

```tsx
// BlogPosting Schema에 author를 항상 포함
const blogJsonLd = {
  '@context': 'https://schema.org',
  '@type': 'BlogPosting',
  headline: post.frontmatter.title,
  author: {
    '@type': 'Person',
    name: '이성',
    url: 'https://example.com/about',  // 저자 페이지로 링크
  },
  datePublished: post.frontmatter.date,
  dateModified: post.frontmatter.date,
}
```

### 직접 경험 보여주기

AI는 원본 데이터와 직접 경험을 높이 평가한다.

```markdown
<!-- 일반적인 설명 (다른 곳에서도 볼 수 있음) -->
useSearchParams는 Suspense로 감싸야 한다.

<!-- 직접 경험 (고유한 콘텐츠) -->
pnpm build 시 "useSearchParams() should be wrapped in
a suspense boundary" 에러가 발생했다.
원인은 Next.js가 빌드 시점에 searchParams 값을 모르기 때문이다.
서버/클라이언트 컴포넌트를 분리하고 Suspense로 감싸서 해결했다.
```

## 7. 콘텐츠 최신성 유지

AI 검색엔진은 최신 정보를 선호한다. sitemap의 `lastModified`와 Schema의 `dateModified`를 정확하게 유지한다.

```tsx
// sitemap.ts에서 lastModified를 정확하게
const blogEntries = posts.map((post) => ({
  url: `https://example.com/blog/${post.slug}`,
  lastModified: new Date(post.frontmatter.date),
}))
```

기존 글도 주기적으로 업데이트한다 — 새로운 데이터 추가, 예제 갱신, 결론 보완. "최종 수정일"을 표시하면 신선도 시그널이 된다.

## 8. 새로운 측정 지표

전통적인 SEO 지표(순위, CTR, 트래픽) 외에 GEO 고유의 지표가 등장하고 있다.

| 지표 | 설명 |
|------|------|
| **AI Visibility Score** | AI 응답에 내 콘텐츠가 나타나는 빈도 |
| **Source Citations** | AI 모델이 내 사이트를 직접 인용한 횟수 |
| **AI Share of Voice** | 특정 주제에서 내 브랜드가 언급되는 비율 |
| **Query Coverage** | 내 콘텐츠가 인식되는 질문의 범위 |

### 측정 도구

- **Ahrefs Brand Radar** — SEO + AI 지표 통합 (월 $99~)
- **Otterly AI** — AI 검색 감사 (월 $29~)
- 직접 확인: Perplexity, ChatGPT에 자기 블로그 주제를 질문하고 인용되는지 확인

## 정리: GEO 체크리스트

**기술적 설정:**
- [ ] `robots.ts`에서 AI 크롤러(GPTBot, PerplexityBot 등) 허용
- [ ] `llms.txt` 생성 (사이트의 핵심 콘텐츠 안내)
- [ ] FAQPage Schema 적용
- [ ] Person Schema로 저자 정보 구조화

**콘텐츠 전략:**
- [ ] 각 섹션 첫 40~60단어에 핵심 답변 배치
- [ ] 글당 5~8개 신뢰할 수 있는 외부 출처 인용
- [ ] 통계와 수치 데이터 포함
- [ ] 질문형 헤딩 사용
- [ ] 문단 60~100단어(한국어 150~250자)로 유지
- [ ] FAQ 섹션 추가 (5~10개 질문)

**권위 구축:**
- [ ] 상세한 저자 소개 페이지
- [ ] 모든 글에 일관된 저자 귀속
- [ ] 직접 경험 기반 콘텐츠 (케이스 스터디, 에러 해결)
- [ ] 정기적인 콘텐츠 업데이트

## 참고

- [GEO: Generative Engine Optimization 논문](https://arxiv.org/abs/2311.09735)
- [llms.txt 표준 명세](https://llmstxt.org/)
- [Conductor 2026 AEO/GEO Benchmarks Report](https://www.conductor.com/academy/aeo-geo-benchmarks-report/)
- [Google AI Overviews 랭킹 요소 분석](https://wellows.com/blog/google-ai-overviews-ranking-factors/)
- [Neil Patel: GEO vs SEO](https://neilpatel.com/blog/geo-vs-seo/)

---

이 글로 SEO + GEO 시리즈를 마무리한다. 1편부터 5편까지의 흐름:

1. 검색엔진은 어떻게 동작하는가 (SEO 기초)
2. Next.js에서 검색엔진에 내 사이트를 알리는 법 (Metadata, sitemap)
3. 검색 결과를 풍부하게 만드는 법 (JSON-LD, Core Web Vitals)
4. AI 검색은 어떻게 동작하는가 (GEO 기초)
5. Next.js에서 AI 검색에 내 콘텐츠를 인용시키는 법 (GEO 실전)

SEO가 "검색되는 것"이었다면, GEO는 "인용되는 것"이다. 둘 다 결국 **좋은 콘텐츠를 만들고, 기계가 이해할 수 있게 구조화하는 것**이라는 점에서 본질은 같다.
